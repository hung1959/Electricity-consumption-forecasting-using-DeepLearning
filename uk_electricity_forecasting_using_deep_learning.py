# -*- coding: utf-8 -*-
"""UK electricity forecasting using deep learning

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kdaqF-uvlh3X9EzRa9zUIA6hLRF5szr3
"""

import pandas as pd

df2 = pd.read_csv('UK_electricity_consumption.csv')
df2.head(30)

df2['Date'] = pd.to_datetime(df2['settlement_date'])

df3 = df2[['Date','nd']]
df_monthly = df3.resample('M', on='Date').mean()
df_monthly.reset_index()

df_monthly['Date'] = df_monthly.index

df_monthly

df_monthly.describe()

df_monthly.isna().any()

import pandas as pd
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(df_monthly['Date'], df_monthly['nd'])
plt.xlabel('Time')
plt.ylabel('Electricity Consumption')
plt.title('Electricity Consumption Scatter Plot')
plt.show()

plt.figure(figsize=(15, 6))
plt.plot(df_monthly['Date'], df_monthly['nd'])
plt.xlabel('Time')
plt.ylabel('Electricity Consumption')
plt.title('Electricity Consumption Line Plot')
plt.show()

import plotly.express as px

actual_line = px.line(df_monthly, x='Date', y='nd', title='Electricity Consumption in the UK')
actual_line

plt.boxplot(df_monthly['nd'])
plt.ylabel('Electricity Consumption')
plt.title('Electricity Consumption Distribution')
plt.show()

trim_size = int(len(df3) * 0.05)
trim_size

Q1 = df_monthly['nd'].quantile(0.25)
Q3 = df_monthly['nd'].quantile(0.75)
IQR = Q3 - Q1

# Remove the outliners located out of the IQR
filtered_df = df_monthly[(df_monthly['nd'] >= Q1 - 1.5 * IQR) & (df_monthly['nd'] <= Q3 + 1.5 * IQR)]

print("Original data:")
print(df_monthly)

print("\nFiltered data:")
print(filtered_df)

import numpy as np
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(filtered_df[['nd']])

train_size = int(len(scaled_data) * 0.70)
train_data = scaled_data[:train_size]
test_data = scaled_data[train_size:]
validation_data = scaled_data[:int(len(scaled_data) * 0.80)]

train = np.array(train_data)
test = np.array(test_data)
validation = np.array(validation_data)

print(train)
print(test)
print(validation)

from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator
time_steps = 12

train_generator = TimeseriesGenerator(train, train, length=time_steps, batch_size=1)
test_generator = TimeseriesGenerator(test, test, length=time_steps, batch_size=1)
validation_generator = TimeseriesGenerator(validation, validation, length=time_steps, batch_size=1)

for i in range(len(train_generator)):
    x_train, y_train = train_generator[i]
    print('Batch', i+1)
    print('Input train:', x_train)
    print('Output train:', y_train)
    print('---------------------')

for j in range(len(test_generator)):
    x_test, y_test = test_generator[j]
    print('Batch', j+1)
    print('Input test:', x_test)
    print('Output test:', y_test)
    print('---------------------')

actual_lstm_data = []
for i in range(len(test_generator)):
    x_test, y_test = test_generator[i]
    actual_lstm_data.append(y_test[0])

actual_data = np.array(actual_lstm_data)
actual_data.flatten()
actual_data

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.regularizers import l1, l2
import time

start_time_lstm = time.time()

lstm_model = Sequential()
lstm_model.add(LSTM(128, return_sequences=True, input_shape=(time_steps, 1)))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(128, return_sequences=True))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(64))
lstm_model.add(Dropout(0.2))
lstm_model.add(Dense(1))
lstm_model.compile(optimizer='adam', loss='mse')

lstm = lstm_model.fit(train_generator, epochs=15, batch_size=32, validation_data=validation_generator)

end_time_lstm = time.time()
computational_time_lstm = end_time_lstm - start_time_lstm

lstm_predictions = lstm_model.predict(test_generator)
print('Computational time: ', computational_time_lstm)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.regularizers import l1, l2

start_time_lstm = time.time()

lstm_model = Sequential()
lstm_model.add(LSTM(128, return_sequences=True, input_shape=(time_steps, 1), kernel_regularizer=l2(0.01)))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(128, return_sequences=True))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(64))
lstm_model.add(Dropout(0.2))
lstm_model.add(Dense(1))
lstm_model.compile(optimizer='rmsprop', loss='mse')

lstm = lstm_model.fit(train_generator, epochs=15, batch_size=32, validation_data=test_generator)

end_time_lstm = time.time()
computational_time_lstm = end_time_lstm - start_time_lstm

lstm_predictions = lstm_model.predict(test_generator)
print('Computational time: ', computational_time_lstm)

from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import GridSearchCV
from keras.models import Sequential
from keras.layers import LSTM, Dense
from keras.metrics import MeanSquaredError

X_train = []
y_train = []

for batch_X, batch_y in train_generator:
    X_train.append(batch_X)
    y_train.append(batch_y)

# Concatenate and reshape the data
X_train = np.concatenate(X_train)
y_train = np.concatenate(y_train)

def create_lstm_model(units=32, activation='relu'):
    lstm_model = Sequential()
    lstm_model.add(LSTM(units, return_sequences=True, input_shape=(time_steps, 1), kernel_regularizer=l2(0.01)))
    lstm_model.add(Dropout(0.2))
    lstm_model.add(LSTM(units, return_sequences=True))
    lstm_model.add(Dropout(0.2))
    lstm_model.add(LSTM(units))
    lstm_model.add(Dropout(0.2))
    lstm_model.add(Dense(1))
    lstm_model.compile(optimizer='adam', loss='mse')
    return lstm_model

lstm_model = KerasRegressor(build_fn=create_lstm_model, verbose=0)

param_grid = {
    'units': [64, 128],
    'activation': ['relu', 'tanh'],
    'epochs': [10, 15],
    'batch_size': [16, 32]
}

grid_search = GridSearchCV(estimator=lstm_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')
grid_search.fit(X_train, y_train)

best_params = grid_search.best_params_
best_score = grid_search.best_score_

print("Best Parameters:", best_params)
print("Best Score:", best_score)

import pandas as pd
import matplotlib.pyplot as plt

plt.plot(lstm.history['loss'], label='Training Loss')
plt.plot(lstm.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Test

import pandas as pd
import matplotlib.pyplot as plt

plt.plot(lstm.history['loss'], label='Training Loss')
plt.plot(lstm.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

results = lstm_model.evaluate(test_generator)

lstm_predictions

lstm_reversed_value = scaler.inverse_transform(lstm_predictions.reshape(-1, 1))
lstm_reversed_value

original_value = scaler.inverse_transform(actual_data.reshape(-1, 1))
original_value

lstm_result = pd.DataFrame({'Actual': original_value.flatten(), 'Predictions': lstm_reversed_value.flatten()})
lstm_result

import matplotlib.pyplot as plt

x = filtered_df['Date'][-len(test_generator):]

plt.figure(figsize=(12,6))
plt.plot(x, original_value, label='Actual Values')
plt.plot(x, lstm_reversed_value, label='Predicted Values')

plt.xlabel('Time Step')
plt.ylabel('Value')
plt.legend()
plt.show()

def prepare_input_data(data, time_steps):
    X = []
    for i in range(len(data) - time_steps):
        X.append(data[i:i+time_steps])
    return np.array(X)

time_steps = 12  # Number of time steps used in forecasting
input_data = prepare_input_data(lstm_predictions, time_steps)

# Make future prediction
last_input_data = input_data[-1].reshape(1, time_steps, 1)  # Take the last value for the input
n_steps = 60  # Number of values for forecasting in the future
forecasts = []
for _ in range(n_steps):
    forecast = lstm_model.predict(last_input_data)
    forecasts.append(forecast[0, 0])
    last_input_data = np.append(last_input_data[:, 1:, :], forecast.reshape(1, 1, 1), axis=1)


forecasts

lstm_reversed_predicted = scaler.inverse_transform(np.array(forecasts).reshape(-1, 1))
lstm_reversed_predicted

new_data = train_data + forecasts

# Biểu đồ so sánh dữ liệu thực tế và dự đoán
x = filtered_df['Date'][-len(test_generator):]
# x = list(range(len(filtered_df['Date'][-len(test_generator):])))
forecast_days = pd.date_range(start=x.iloc[-1], periods=n_steps, freq='M')
# x_new = list(range(len(filtered_df['Date'][-len(test_generator):]), len(filtered_df['Date'][-len(test_generator):]) + len(forecasts)))


plt.figure(figsize=(14,6))
plt.plot(x, actual_data, label='Actual')
plt.plot(x, lstm_predictions, label='Predicted')
plt.plot(forecast_days, forecasts, label='Forecast')
plt.xlabel('Time')
plt.ylabel('Value')
plt.legend()
plt.show()

x = filtered_df['Date'][-len(test_generator):]

forecast_days = pd.date_range(start=x.iloc[-1], periods=n_steps, freq='M')

plt.figure(figsize=(14,6))
plt.plot(x, original_value, label='Actual Values')
plt.plot(x, lstm_reversed_value, label='Predicted Values')
plt.plot(forecast_days, lstm_reversed_predicted, label='Forecast')
plt.xlabel('Time')
plt.ylabel('Value')
plt.legend()
plt.show()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense, Dropout

start_time_rnn = time.time()

simplernn_model = Sequential()
simplernn_model.add(SimpleRNN(128, return_sequences=True, input_shape=(time_steps, 1)))
simplernn_model.add(Dropout(0.2))
simplernn_model.add(SimpleRNN(128, return_sequences=True))
simplernn_model.add(Dropout(0.2))
simplernn_model.add(SimpleRNN(128))
simplernn_model.add(Dropout(0.2))
simplernn_model.add(Dense(1))
simplernn_model.compile(optimizer='adam', loss='mse')

rnn = simplernn_model.fit(train_generator, epochs=15, batch_size=32, validation_data=validation_generator)

end_time_rnn = time.time()
computational_time_rnn = end_time_rnn - start_time_rnn

simplernn_predictions = simplernn_model.predict(test_generator)
print('Computational time: ', computational_time_rnn)

simplernn_results = simplernn_model.evaluate(test_generator)

simplernn_predictions

import matplotlib.pyplot as plt

plt.plot(rnn.history['loss'], label='Training Loss')
plt.plot(rnn.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

simplernn_reversed_value = scaler.inverse_transform(simplernn_predictions.reshape(-1, 1))
simplernn_reversed_value

import matplotlib.pyplot as plt

# x = list(range(len(original_value)))
x = filtered_df['Date'][-len(test_generator):]

plt.figure(figsize=(15,6))
plt.plot(x, original_value, label='Actual Values')
plt.plot(x, simplernn_reversed_value, label='Predicted Values')

plt.xlabel('Time Step')
plt.ylabel('Value')
plt.legend()
plt.show()

from keras.layers import GRU

start_time_gru = time.time()

gru_model = Sequential()
gru_model.add(GRU(units=128, return_sequences=True, input_shape=(time_steps, 1)))
gru_model.add(Dropout(0.2))
gru_model.add(GRU(units=128, return_sequences=True))
gru_model.add(Dropout(0.2))
gru_model.add(GRU(units=128))
gru_model.add(Dropout(0.2))
gru_model.add(Dense(units=1))

gru_model.compile(optimizer='adam', loss='mse')

gru = gru_model.fit(train_generator, epochs=15, batch_size=32, validation_data=validation_generator)

end_time_gru = time.time()
computational_time_gru = end_time_gru - start_time_gru

gru_predictions = gru_model.predict(test_generator)
print('Computational time: ', computational_time_gru)

gru_results = gru_model.evaluate(test_generator)

plt.plot(gru.history['loss'], label='Training Loss')
plt.plot(gru.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.plot(gru.history['loss'], label='Training Loss')
plt.plot(gru.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

gru_predictions

gru_reversed_value = scaler.inverse_transform(gru_predictions.reshape(-1, 1))
gru_reversed_value

plt.figure(figsize=(12,6))
plt.plot(x, original_value, label='Actual Values')
plt.plot(x, gru_reversed_value, label='Predicted Values')

plt.xlabel('Time Step')
plt.ylabel('Value')
plt.legend()
plt.show()

def prepare_input_data(data, time_steps):
    X = []
    for i in range(len(data) - time_steps):
        X.append(data[i:i+time_steps])
    return np.array(X)

time_steps = 12  # Number of time steps used in forecasting
gru_input_data = prepare_input_data(gru_predictions, time_steps)

# Make future prediction
gru_last_input_data = gru_input_data[-1].reshape(1, time_steps, 1)  # Take the last value for the input
n_steps = 60  # Number of values for forecasting in the future
gru_forecasts = []
for _ in range(n_steps):
    forecast = gru_model.predict(gru_last_input_data)
    gru_forecasts.append(forecast[0, 0])
    gru_last_input_data = np.append(gru_last_input_data[:, 1:, :], forecast.reshape(1, 1, 1), axis=1)

gru_forecasts

gru_reversed_predicted = scaler.inverse_transform(np.array(gru_forecasts).reshape(-1, 1))
gru_reversed_predicted

x = filtered_df['Date'][-len(test_generator):]

forecast_days = pd.date_range(start=x.iloc[-1], periods=n_steps, freq='M')

plt.figure(figsize=(10,6))
plt.plot(x, original_value, label='Actual')
plt.plot(x, gru_reversed_value, label='Predicted')
plt.plot(forecast_days, gru_reversed_predicted, label='Forecast')
plt.xlabel('Time')
plt.ylabel('Value')
plt.legend()
plt.show()

from tensorflow.keras.models import Sequential
from keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout

start_time_cnn = time.time()

cnn_model = Sequential()
cnn_model.add(Conv1D(128, kernel_size=5, activation='relu', input_shape=(time_steps, 1)))
cnn_model.add(Dropout(0.2))
cnn_model.add(LSTM(64, return_sequences=True, activation='relu'))
cnn_model.add(Dropout(0.2))
cnn_model.add(LSTM(64, activation='relu'))
cnn_model.add(Dropout(0.2))
cnn_model.add(Dense(1))

cnn_model.compile(optimizer='adam', loss='mse')
cnn = cnn_model.fit(train_generator, epochs=15, batch_size=16, validation_data=validation_generator)

end_time_cnn = time.time()
computational_time_cnn = end_time_cnn - start_time_cnn

cnn_predictions = cnn_model.predict(test_generator)
print('Computational time: ', computational_time_cnn)

cnn_result = cnn_model.evaluate(test_generator)

import matplotlib.pyplot as plt

plt.plot(cnn.history['loss'], label='Training Loss')
plt.plot(cnn.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

cnn_predictions

cnn_reversed_value = scaler.inverse_transform(cnn_predictions.reshape(-1, 1))
cnn_reversed_value

x = filtered_df['Date'][-len(test_generator):]

plt.figure(figsize=(12,6))
plt.plot(x, original_value, label='Actual Values')
plt.plot(x, cnn_reversed_value, label='Predicted Values')

plt.xlabel('Time Step')
plt.ylabel('Value')
plt.legend()
plt.show()

def prepare_input_data(data, time_steps):
    X = []
    for i in range(len(data) - time_steps):
        X.append(data[i:i+time_steps])
    return np.array(X)

time_steps = 12  #
cnn_input_data = prepare_input_data(cnn_predictions, time_steps)

#
cnn_last_input_data = cnn_input_data[-1].reshape(1, time_steps, 1)  #
n_steps = 60  #
cnn_forecasts = []
for _ in range(n_steps):
    forecast = cnn_model.predict(cnn_last_input_data)
    cnn_forecasts.append(forecast[0, 0])
    cnn_last_input_data = np.append(cnn_last_input_data[:, 1:, :], forecast.reshape(1, 1, 1), axis=1)

cnn_forecasts

cnn_reversed_predicted = scaler.inverse_transform(np.array(cnn_forecasts).reshape(-1, 1))
cnn_reversed_predicted

x = filtered_df['Date'][-len(test_generator):]

forecast_days = pd.date_range(start=x.iloc[-1], periods=n_steps, freq='M')

plt.figure(figsize=(10,6))
plt.plot(x, original_value, label='Actual')
plt.plot(x, cnn_reversed_value, label='Predicted')
plt.plot(forecast_days, cnn_reversed_predicted, label='Forecast')
plt.xlabel('Time')
plt.ylabel('Value')
plt.legend()
plt.show()

pip install git+https://github.com/philipperemy/keras-tcn.git

from tensorflow.keras.models import Sequential
from tcn import TCN
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.regularizers import l1, l2

start_time_tcn = time.time()

tcn_model = Sequential()
tcn_model.add(TCN(input_shape=(time_steps, 1), return_sequences=True, nb_filters=128, kernel_size=3, dilations=[1, 2, 4, 8, 16, 32]))
tcn_model.add(Dropout(0.2))
tcn_model.add(TCN(return_sequences=True, nb_filters=128, kernel_size=3, dilations=[1, 2, 4, 8, 16, 32]))
tcn_model.add(Dropout(0.2))
tcn_model.add(TCN(nb_filters=128, kernel_size=3, dilations=[1, 2, 4, 8, 16, 32]))
tcn_model.add(Dense(1))
tcn_model.compile(optimizer='adam', loss='mse')

tcn = tcn_model.fit(train_generator, epochs=15, batch_size=16, validation_data=validation_generator)

end_time_tcn = time.time()
computational_time_tcn = end_time_tcn - start_time_tcn

tcn_predictions = tcn_model.predict(test_generator)
print('Conputational time: ', computational_time_tcn)

tcn_result = tcn_model.evaluate(test_generator)

import matplotlib.pyplot as plt

plt.plot(tcn.history['loss'], label='Training Loss')
plt.plot(tcn.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

tcn_predictions

tcn_reversed_value = scaler.inverse_transform(tcn_predictions.reshape(-1, 1))
tcn_reversed_value

plt.figure(figsize=(15,6))
plt.plot(x, original_value, label='Actual Values')
plt.plot(x, tcn_reversed_value, label='Predicted Values')

plt.xlabel('Time Step')
plt.ylabel('Value')
plt.legend()
plt.show()

def prepare_input_data(data, time_steps):
    X = []
    for i in range(len(data) - time_steps):
        X.append(data[i:i+time_steps])
    return np.array(X)

time_steps = 12  #
tcn_input_data = prepare_input_data(tcn_predictions, time_steps)

#
tcn_last_input_data = tcn_input_data[-1].reshape(1, time_steps, 1)  #
n_steps = 60  #
tcn_forecasts = []
for _ in range(n_steps):
    forecast = tcn_model.predict(tcn_last_input_data)
    tcn_forecasts.append(forecast[0, 0])
    tcn_last_input_data = np.append(tcn_last_input_data[:, 1:, :], forecast.reshape(1, 1, 1), axis=1)

tcn_forecasts

tcn_reversed_predicted = scaler.inverse_transform(np.array(tcn_forecasts).reshape(-1, 1))
tcn_reversed_predicted

x = filtered_df['Date'][-len(test_generator):]

forecast_days = pd.date_range(start=x.iloc[-1], periods=n_steps, freq='M')

plt.figure(figsize=(10,6))
plt.plot(x, original_value, label='Actual')
plt.plot(x, tcn_reversed_value, label='Predicted')
plt.plot(forecast_days, tcn_reversed_predicted, label='Forecast')
plt.xlabel('Time')
plt.ylabel('Value')
plt.legend()
plt.show()

from statsmodels.tsa.arima.model import ARIMA

start_time_arima = time.time()

arima_model = ARIMA(train_data, order=(12, 1, 12))
arima_model_fit = arima_model.fit()

end_time_arima = time.time()
computational_time_arima = end_time_arima - start_time_arima

arima_predictions = arima_model_fit.predict(start=train_size, end=len(scaled_data)-1)
print('Computational time: ', computational_time_arima)

arima_predictions = np.reshape(arima_predictions, (len(arima_predictions), 1))
arima_predictions

arima_reversed_predicted = scaler.inverse_transform(arima_predictions.reshape(-1, 1))
arima_reversed_predicted

test_data_2d = np.reshape(test_data, (len(test_data), 1))
test_data_2d

test_data_original = scaler.inverse_transform(test_data_2d.reshape(-1, 1))
test_data_original

arima_result = pd.DataFrame({'Actual': test_data_original.flatten(), 'Predictions': arima_reversed_predicted.flatten()})
arima_result

import matplotlib.pyplot as plt

x = list(range(len(arima_predictions)))

plt.figure(figsize=(12,6))
plt.plot(x, arima_result['Actual'], label='Actual Values')
plt.plot(x, arima_result['Predictions'], label='Predicted Values')

plt.xlabel('Time Step')
plt.ylabel('Value')
plt.legend()
plt.show()

n_forecast = 60
arima_forecast = arima_model_fit.forecast(steps=n_forecast)
arima_forecast_reversed = scaler.inverse_transform(np.array(arima_forecast).reshape(-1, 1))

x = filtered_df['Date'][-len(arima_predictions):]

forecast_days = pd.date_range(start=x.iloc[-1], periods=n_forecast, freq='M')

plt.figure(figsize=(14,6))
plt.plot(x, arima_result['Actual'], label='Actual')
plt.plot(x, arima_result['Predictions'], label='Predicted Values')
plt.plot(forecast_days, arima_forecast_reversed, label='Forecast')
plt.xlabel('Date')
plt.ylabel('Value')
plt.title('ARIMA Forecasting')
plt.legend()
plt.show()

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

lstm_mae = mean_absolute_error(original_value, lstm_reversed_value)
print('Mean Absolute Error (MAE):', lstm_mae)

lstm_mse = mean_squared_error(original_value, lstm_reversed_value)
print('Mean Squared Error (MSE):', lstm_mse)

lstm_rmse = np.sqrt(lstm_mse)
print('Root Mean Squared Error (RMSE):', lstm_rmse)

lstm_r2 = r2_score(original_value, lstm_reversed_value)
print('Coefficient of Determination (R-squared):', lstm_r2)

def mspe(actual_values, predicted_values):
    n = len(actual_values)
    mspe = np.mean((actual_values - predicted_values) ** 2)
    return mspe

print('Mean Squared Prediction Error (MAPE): ', mspe(original_value, lstm_reversed_value))

srnn_mae = mean_absolute_error(original_value, simplernn_reversed_value)
print('Mean Absolute Error (MAE):', srnn_mae)

srnn_mse = mean_squared_error(original_value, simplernn_reversed_value)
print('Mean Squared Error (MSE):', srnn_mse)

srnn_rmse = np.sqrt(srnn_mse)
print('Root Mean Squared Error (RMSE):', srnn_rmse)

srnn_r2 = r2_score(original_value, simplernn_reversed_value)
print('Coefficient of Determination (R-squared):', srnn_r2)

gru_mae = mean_absolute_error(original_value, gru_reversed_value)
print('Mean Absolute Error (MAE):', gru_mae)

gru_mse = mean_squared_error(original_value, gru_reversed_value)
print('Mean Squared Error (MSE):', gru_mse)

gru_rmse = np.sqrt(gru_mse)
print('Root Mean Squared Error (RMSE):', gru_rmse)

gru_r2 = r2_score(original_value, gru_reversed_value)
print('Coefficient of Determination (R-squared):', gru_r2)

cnn_mae = mean_absolute_error(original_value, cnn_reversed_value)
print('Mean Absolute Error (MAE):', cnn_mae)

cnn_mse = mean_squared_error(original_value, cnn_reversed_value)
print('Mean Squared Error (MSE):', cnn_mse)

cnn_rmse = np.sqrt(cnn_mse)
print('Root Mean Squared Error (RMSE):', cnn_rmse)

cnn_r2 = r2_score(original_value, cnn_reversed_value)
print('Coefficient of Determination (R-squared):', cnn_r2)

tcn_mae = mean_absolute_error(original_value, tcn_reversed_value)
print('Mean Absolute Error (MAE):', tcn_mae)

tcn_mse = mean_squared_error(original_value, tcn_reversed_value)
print('Mean Squared Error (MSE):', tcn_mse)

tcn_rmse = np.sqrt(tcn_mse)
print('Root Mean Squared Error (RMSE):', tcn_rmse)

tcn_r2 = r2_score(original_value, tcn_reversed_value)
print('Coefficient of Determination (R-squared):', tcn_r2)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

arima_mae = mean_absolute_error(arima_result['Actual'], arima_result['Predictions'])
print('Mean Absolute Error (MAE):', arima_mae)

arima_mse = mean_squared_error(arima_result['Actual'], arima_result['Predictions'])
print('Mean Squared Error (MSE):', arima_mse)

arima_rmse = np.sqrt(arima_mse)
print('Root Mean Squared Error (RMSE):', arima_rmse)

arima_r2 = r2_score(arima_result['Actual'], arima_result['Predictions'])
print('Coefficient of Determination (R-squared):', arima_r2)

import sys
print(sys.version)

import keras
print(keras.__version__)

import tensorflow as tf
print(tf.__version__)

x = filtered_df['Date'][-len(test_generator):]

forecast_days = pd.date_range(start=x.iloc[-1], periods=n_steps, freq='M')

plt.figure(figsize=(14,7))
plt.plot(x, original_value, label='Actual')
plt.plot(x, lstm_reversed_value, label='LSTM Prediction')

plt.plot(x, simplernn_reversed_value, label='SRNN Prediction')

plt.plot(x, gru_reversed_value, label='GRU Prediction')

plt.plot(x, cnn_reversed_value, label='CNN Prediction')

plt.plot(x, tcn_reversed_value, label='TCN Predicted')

plt.plot(filtered_df['Date'][-len(arima_predictions):], arima_result['Predictions'], label='ARIMA Prediction')

plt.xlabel('Time')
plt.ylabel('Value')
plt.legend()
plt.show()

x = filtered_df['Date'][-len(test_generator):]

forecast_days = pd.date_range(start=x.iloc[-1], periods=n_steps, freq='M')

plt.figure(figsize=(14,8))
plt.plot(x, original_value, label='Actual')
plt.plot(forecast_days, lstm_reversed_predicted, label='LSTM Forecast')

plt.plot(forecast_days, gru_reversed_predicted, label='GRU Forecast')

plt.plot(forecast_days, cnn_reversed_predicted, label='CNN Forecast')

plt.plot(forecast_days, tcn_reversed_predicted, label='TCN Forecast')

plt.plot(forecast_days, arima_forecast_reversed, label='ARIMA Forecast')
plt.xlabel('Time')
plt.ylabel('Value')
plt.legend()
plt.show()

df_comparison = pd.DataFrame({'Time': filtered_df['Date'][-len(test_generator):],'Actual': original_value.flatten(), 'LSTM': lstm_reversed_value.flatten(), 'SRNN': simplernn_reversed_value.flatten(), 'GRU': gru_reversed_value.flatten(), 'CNN': cnn_reversed_value.flatten(), 'TCN': tcn_reversed_value.flatten(), 'ARIMA': arima_result['Predictions'][12:].values})
df_comparison

df_forecast = pd.DataFrame({'Time': forecast_days, 'LSTM': lstm_reversed_predicted.flatten(), 'GRU': gru_reversed_predicted.flatten(), 'CNN': cnn_reversed_predicted.flatten(), 'TCN': tcn_reversed_predicted.flatten(), 'ARIMA': arima_forecast_reversed.flatten()})
df_forecast

import plotly.express as px

fig_line = px.line(df_comparison, x='Time', y=['Actual', 'LSTM', 'SRNN', 'GRU', 'CNN', 'TCN', 'ARIMA'], title='Performance Comparison')
fig_line

forecast_line = px.line(df_forecast, x = 'Time', y=['LSTM', 'GRU', 'CNN', 'TCN', 'ARIMA'], title='Future Forecasting')
forecast_line